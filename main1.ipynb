{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "import string\n",
    "from spacy import displacy\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = api.load(\"glove-wiki-gigaword-50\")\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytextrank\n",
    "import neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# python -m spacy download en_core_web_sm\n",
    "# python -m spacy download en_core_web_md\n",
    "# ---------------------------------------\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_raw():\n",
    "    with open(\"data.txt\",'r') as fh:\n",
    "        txt = fh.readlines()\n",
    "    return str(txt[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = get_data_raw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Is this a crash event?\n",
    "## 2. How many vehicles were involved in the crash?\n",
    "## 3. What were the types of the vehicles?\n",
    "## 4. What was the type of the collision?\n",
    "## 5. Where did this happen? (highway/city, straight road/intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp =  spacy.load(\"en_core_web_md\")\n",
    "try:\n",
    "    nlp.add_pipe(nlp.create_pipe('sentencizer')) \n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    neuralcoref.add_to_pipe(nlp)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from spacy.matcher import Matcher\n",
    "nounPhrase_posExclude = ['PRON', 'DET', 'PART', 'ADJ']\n",
    "\n",
    "with doc.retokenize() as retokenizer:\n",
    "  \n",
    "    for noun_phrase in list(doc.noun_chunks):\n",
    "        cur_span = []\n",
    "       \n",
    "        for item in noun_phrase:\n",
    "            if item.pos_ not in nounPhrase_posExclude:\n",
    "                cur_span.append(item)\n",
    "        if len(cur_span) > 1:       \n",
    "            _span = doc[cur_span[0].i : cur_span[-1].i ]\n",
    "        \n",
    "            retokenizer.merge(\n",
    "               _span\n",
    "            )\n",
    "    \n",
    "    # ================================\n",
    "    # Handle terms like \"t-boned\", \"rear-ended\", \"side-swiped\"\n",
    "    # ================================\n",
    "    pattern = [{\"POS\": \"NOUN\"}, {\"ORTH\":'-'} , {\"POS\": \"VERB\"}]\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add( 'NV' ,None,pattern)\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id] \n",
    "        span = doc[start:end]  \n",
    "#         print(match_id, string_id, start, end, span.text)\n",
    "\n",
    "        retokenizer.merge(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sent.string.strip() for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens\n",
    "tokens = [token for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "I  Is stop word/punctuation ? True  POS  PRON Lemma  -PRON-\n",
      "pulled  Is stop word/punctuation ? False  POS  VERB Lemma  pull\n",
      "out  Is stop word/punctuation ? True  POS  SCONJ Lemma  out\n",
      "of  Is stop word/punctuation ? True  POS  ADP Lemma  of\n",
      "my  Is stop word/punctuation ? True  POS  DET Lemma  -PRON-\n",
      "parking  Is stop word/punctuation ? False  POS  NOUN Lemma  park\n",
      "spot  Is stop word/punctuation ? False  POS  NOUN Lemma  spot\n",
      ",  Is stop word/punctuation ? True  POS  PUNCT Lemma  ,\n",
      "turned  Is stop word/punctuation ? False  POS  VERB Lemma  turn\n",
      "right  Is stop word/punctuation ? False  POS  ADV Lemma  right\n",
      "out  Is stop word/punctuation ? True  POS  SCONJ Lemma  out\n",
      "of  Is stop word/punctuation ? True  POS  ADP Lemma  of\n",
      "the  Is stop word/punctuation ? True  POS  DET Lemma  the\n",
      "parking  Is stop word/punctuation ? False  POS  NOUN Lemma  park\n",
      "lot  Is stop word/punctuation ? False  POS  NOUN Lemma  lot\n",
      ",  Is stop word/punctuation ? True  POS  PUNCT Lemma  ,\n",
      "then  Is stop word/punctuation ? True  POS  ADV Lemma  then\n",
      "proceeded  Is stop word/punctuation ? False  POS  VERB Lemma  proceed\n",
      "to  Is stop word/punctuation ? True  POS  ADP Lemma  to\n",
      "the  Is stop word/punctuation ? True  POS  DET Lemma  the\n",
      "next  Is stop word/punctuation ? True  POS  ADJ Lemma  next\n",
      "stop  Is stop word/punctuation ? False  POS  NOUN Lemma  stop\n",
      "sign  Is stop word/punctuation ? False  POS  NOUN Lemma  sign\n",
      ".  Is stop word/punctuation ? True  POS  PUNCT Lemma  .\n",
      "----\n",
      "While  Is stop word/punctuation ? True  POS  SCONJ Lemma  while\n",
      "looking  Is stop word/punctuation ? False  POS  VERB Lemma  look\n",
      "both  Is stop word/punctuation ? True  POS  DET Lemma  both\n",
      "ways  Is stop word/punctuation ? False  POS  NOUN Lemma  way\n",
      "I  Is stop word/punctuation ? True  POS  PRON Lemma  -PRON-\n",
      "noticed  Is stop word/punctuation ? False  POS  VERB Lemma  notice\n",
      "a  Is stop word/punctuation ? True  POS  DET Lemma  a\n",
      "white  Is stop word/punctuation ? False  POS  ADJ Lemma  white\n",
      "truck  Is stop word/punctuation ? False  POS  NOUN Lemma  truck\n",
      "in  Is stop word/punctuation ? True  POS  ADP Lemma  in\n",
      "the  Is stop word/punctuation ? True  POS  DET Lemma  the\n",
      "far  Is stop word/punctuation ? False  POS  ADJ Lemma  far\n",
      "distance  Is stop word/punctuation ? False  POS  NOUN Lemma  distance\n",
      "and  Is stop word/punctuation ? True  POS  CCONJ Lemma  and\n",
      "proceeded  Is stop word/punctuation ? False  POS  VERB Lemma  proceed\n",
      "to  Is stop word/punctuation ? True  POS  PART Lemma  to\n",
      "roll  Is stop word/punctuation ? False  POS  VERB Lemma  roll\n",
      "forward  Is stop word/punctuation ? False  POS  ADV Lemma  forward\n",
      "and  Is stop word/punctuation ? True  POS  CCONJ Lemma  and\n",
      "take  Is stop word/punctuation ? True  POS  VERB Lemma  take\n",
      "the  Is stop word/punctuation ? True  POS  DET Lemma  the\n",
      "left  Is stop word/punctuation ? False  POS  ADJ Lemma  left\n",
      "turn  Is stop word/punctuation ? False  POS  NOUN Lemma  turn\n",
      ".  Is stop word/punctuation ? True  POS  PUNCT Lemma  .\n",
      "----\n",
      "As  Is stop word/punctuation ? True  POS  SCONJ Lemma  as\n",
      "I  Is stop word/punctuation ? True  POS  PRON Lemma  -PRON-\n",
      "turned  Is stop word/punctuation ? False  POS  VERB Lemma  turn\n",
      "I  Is stop word/punctuation ? True  POS  PRON Lemma  -PRON-\n",
      "was  Is stop word/punctuation ? True  POS  AUX Lemma  be\n",
      "t-boned  Is stop word/punctuation ? False  POS  VERB Lemma  t-boned\n",
      "on  Is stop word/punctuation ? True  POS  ADP Lemma  on\n",
      "the  Is stop word/punctuation ? True  POS  DET Lemma  the\n",
      "front  Is stop word/punctuation ? True  POS  ADJ Lemma  front\n",
      "driver  Is stop word/punctuation ? False  POS  NOUN Lemma  driver\n",
      "side  Is stop word/punctuation ? True  POS  NOUN Lemma  side\n",
      "by  Is stop word/punctuation ? True  POS  ADP Lemma  by\n",
      "the  Is stop word/punctuation ? True  POS  DET Lemma  the\n",
      "white  Is stop word/punctuation ? False  POS  PROPN Lemma  white\n",
      "truck  Is stop word/punctuation ? False  POS  PROPN Lemma  truck\n",
      ",  Is stop word/punctuation ? True  POS  PUNCT Lemma  ,\n",
      "which  Is stop word/punctuation ? True  POS  DET Lemma  which\n",
      "turned  Is stop word/punctuation ? False  POS  VERB Lemma  turn\n",
      "out  Is stop word/punctuation ? True  POS  ADP Lemma  out\n",
      "to  Is stop word/punctuation ? True  POS  PART Lemma  to\n",
      "be  Is stop word/punctuation ? True  POS  AUX Lemma  be\n",
      "a  Is stop word/punctuation ? True  POS  DET Lemma  a\n",
      "Ford F-450 commercial  Is stop word/punctuation ? False  POS  PROPN Lemma  Ford F-450 commercial\n",
      "truck  Is stop word/punctuation ? False  POS  NOUN Lemma  truck\n",
      ".  Is stop word/punctuation ? True  POS  PUNCT Lemma  .\n",
      "----\n",
      "All  Is stop word/punctuation ? True  POS  DET Lemma  all\n",
      "I  Is stop word/punctuation ? True  POS  PRON Lemma  -PRON-\n",
      "remember  Is stop word/punctuation ? False  POS  VERB Lemma  remember\n",
      "hearing  Is stop word/punctuation ? False  POS  VERB Lemma  hear\n",
      "was  Is stop word/punctuation ? True  POS  AUX Lemma  be\n",
      "the  Is stop word/punctuation ? True  POS  DET Lemma  the\n",
      "rumbling  Is stop word/punctuation ? False  POS  NOUN Lemma  rumbling\n",
      "of  Is stop word/punctuation ? True  POS  ADP Lemma  of\n",
      "crushing  Is stop word/punctuation ? False  POS  VERB Lemma  crush\n",
      "metal  Is stop word/punctuation ? False  POS  NOUN Lemma  metal\n",
      ".  Is stop word/punctuation ? True  POS  PUNCT Lemma  .\n",
      "----\n",
      "Needless  Is stop word/punctuation ? False  POS  ADJ Lemma  needless\n",
      "to  Is stop word/punctuation ? True  POS  PART Lemma  to\n",
      "say  Is stop word/punctuation ? True  POS  VERB Lemma  say\n",
      "my  Is stop word/punctuation ? True  POS  DET Lemma  -PRON-\n",
      "beloved  Is stop word/punctuation ? False  POS  ADJ Lemma  beloved\n",
      "car  Is stop word/punctuation ? False  POS  NOUN Lemma  car\n",
      "that  Is stop word/punctuation ? True  POS  DET Lemma  that\n",
      "I  Is stop word/punctuation ? True  POS  PRON Lemma  -PRON-\n",
      "had  Is stop word/punctuation ? True  POS  AUX Lemma  have\n",
      "worked  Is stop word/punctuation ? False  POS  VERB Lemma  work\n",
      "so  Is stop word/punctuation ? True  POS  ADV Lemma  so\n",
      "hard  Is stop word/punctuation ? False  POS  ADV Lemma  hard\n",
      "for  Is stop word/punctuation ? True  POS  ADP Lemma  for\n",
      "appeared  Is stop word/punctuation ? False  POS  VERB Lemma  appear\n",
      "to  Is stop word/punctuation ? True  POS  PART Lemma  to\n",
      "be  Is stop word/punctuation ? True  POS  AUX Lemma  be\n",
      "totaled  Is stop word/punctuation ? False  POS  VERB Lemma  total\n",
      ".  Is stop word/punctuation ? True  POS  PUNCT Lemma  .\n",
      "----\n",
      "All  Is stop word/punctuation ? True  POS  DET Lemma  all\n",
      "of  Is stop word/punctuation ? True  POS  ADP Lemma  of\n",
      "my  Is stop word/punctuation ? True  POS  DET Lemma  -PRON-\n",
      "airbags  Is stop word/punctuation ? False  POS  NOUN Lemma  airbag\n",
      "deployed  Is stop word/punctuation ? False  POS  VERB Lemma  deploy\n",
      ",  Is stop word/punctuation ? True  POS  PUNCT Lemma  ,\n",
      "my  Is stop word/punctuation ? True  POS  DET Lemma  -PRON-\n",
      "front  Is stop word/punctuation ? True  POS  ADJ Lemma  front\n",
      "windshield  Is stop word/punctuation ? False  POS  NOUN Lemma  windshield\n",
      "was  Is stop word/punctuation ? True  POS  AUX Lemma  be\n",
      "smashed  Is stop word/punctuation ? False  POS  VERB Lemma  smash\n",
      "   Is stop word/punctuation ? False  POS  SPACE Lemma   \n",
      "in  Is stop word/punctuation ? True  POS  ADV Lemma  in\n",
      ",  Is stop word/punctuation ? True  POS  PUNCT Lemma  ,\n",
      "the  Is stop word/punctuation ? True  POS  DET Lemma  the\n",
      "driver’s  Is stop word/punctuation ? False  POS  NOUN Lemma  driver’s\n",
      "window  Is stop word/punctuation ? False  POS  NOUN Lemma  window\n",
      "was  Is stop word/punctuation ? True  POS  AUX Lemma  be\n",
      "broken  Is stop word/punctuation ? False  POS  VERB Lemma  break\n",
      ",  Is stop word/punctuation ? True  POS  PUNCT Lemma  ,\n",
      "my  Is stop word/punctuation ? True  POS  DET Lemma  -PRON-\n",
      "key  Is stop word/punctuation ? False  POS  ADJ Lemma  key\n",
      "jammed  Is stop word/punctuation ? False  POS  VERB Lemma  jam\n",
      "in  Is stop word/punctuation ? True  POS  ADP Lemma  in\n",
      "the  Is stop word/punctuation ? True  POS  DET Lemma  the\n",
      "ignition  Is stop word/punctuation ? False  POS  NOUN Lemma  ignition\n",
      ",  Is stop word/punctuation ? True  POS  PUNCT Lemma  ,\n",
      "and  Is stop word/punctuation ? True  POS  CCONJ Lemma  and\n",
      "I  Is stop word/punctuation ? True  POS  PRON Lemma  -PRON-\n",
      "was  Is stop word/punctuation ? True  POS  AUX Lemma  be\n",
      "unconscious  Is stop word/punctuation ? False  POS  ADJ Lemma  unconscious\n",
      ".  Is stop word/punctuation ? True  POS  PUNCT Lemma  .\n",
      "----\n",
      "When  Is stop word/punctuation ? True  POS  ADV Lemma  when\n",
      "I  Is stop word/punctuation ? True  POS  PRON Lemma  -PRON-\n",
      "came  Is stop word/punctuation ? False  POS  VERB Lemma  come\n",
      "to  Is stop word/punctuation ? True  POS  ADP Lemma  to\n",
      "my  Is stop word/punctuation ? True  POS  DET Lemma  -PRON-\n",
      "first  Is stop word/punctuation ? True  POS  ADJ Lemma  first\n",
      "reaction  Is stop word/punctuation ? False  POS  NOUN Lemma  reaction\n",
      "was  Is stop word/punctuation ? True  POS  AUX Lemma  be\n",
      "hysterics  Is stop word/punctuation ? False  POS  NOUN Lemma  hysteric\n",
      ".  Is stop word/punctuation ? True  POS  PUNCT Lemma  .\n",
      "----\n",
      "I  Is stop word/punctuation ? True  POS  PRON Lemma  -PRON-\n",
      "looked  Is stop word/punctuation ? False  POS  VERB Lemma  look\n",
      "around  Is stop word/punctuation ? True  POS  ADV Lemma  around\n",
      "for  Is stop word/punctuation ? True  POS  ADP Lemma  for\n",
      "a  Is stop word/punctuation ? True  POS  DET Lemma  a\n",
      "minute  Is stop word/punctuation ? False  POS  NOUN Lemma  minute\n",
      ",  Is stop word/punctuation ? True  POS  PUNCT Lemma  ,\n",
      "heard  Is stop word/punctuation ? False  POS  VERB Lemma  hear\n",
      "voices  Is stop word/punctuation ? False  POS  NOUN Lemma  voice\n",
      "talking  Is stop word/punctuation ? False  POS  VERB Lemma  talk\n",
      "to  Is stop word/punctuation ? True  POS  ADP Lemma  to\n",
      "me  Is stop word/punctuation ? True  POS  PRON Lemma  -PRON-\n",
      ",  Is stop word/punctuation ? True  POS  PUNCT Lemma  ,\n",
      "then  Is stop word/punctuation ? True  POS  ADV Lemma  then\n",
      "I  Is stop word/punctuation ? True  POS  PRON Lemma  -PRON-\n",
      "felt  Is stop word/punctuation ? False  POS  VERB Lemma  feel\n",
      "an  Is stop word/punctuation ? True  POS  DET Lemma  an\n",
      "unbearable  Is stop word/punctuation ? False  POS  ADJ Lemma  unbearable\n",
      "pain  Is stop word/punctuation ? False  POS  NOUN Lemma  pain\n",
      "in  Is stop word/punctuation ? True  POS  ADP Lemma  in\n",
      "my  Is stop word/punctuation ? True  POS  DET Lemma  -PRON-\n",
      "right  Is stop word/punctuation ? False  POS  ADJ Lemma  right\n",
      "hand  Is stop word/punctuation ? False  POS  NOUN Lemma  hand\n",
      ".  Is stop word/punctuation ? True  POS  PUNCT Lemma  .\n",
      "----\n",
      "As  Is stop word/punctuation ? True  POS  SCONJ Lemma  as\n",
      "I  Is stop word/punctuation ? True  POS  PRON Lemma  -PRON-\n",
      "looked  Is stop word/punctuation ? False  POS  VERB Lemma  look\n",
      "down  Is stop word/punctuation ? True  POS  ADP Lemma  down\n",
      "at  Is stop word/punctuation ? True  POS  ADP Lemma  at\n",
      "my  Is stop word/punctuation ? True  POS  DET Lemma  -PRON-\n",
      "hand  Is stop word/punctuation ? False  POS  NOUN Lemma  hand\n",
      "I  Is stop word/punctuation ? True  POS  PRON Lemma  -PRON-\n",
      "noticed  Is stop word/punctuation ? False  POS  VERB Lemma  notice\n",
      "that  Is stop word/punctuation ? True  POS  SCONJ Lemma  that\n",
      "it  Is stop word/punctuation ? True  POS  PRON Lemma  -PRON-\n",
      "appeared  Is stop word/punctuation ? False  POS  VERB Lemma  appear\n",
      "to  Is stop word/punctuation ? True  POS  PART Lemma  to\n",
      "be  Is stop word/punctuation ? True  POS  AUX Lemma  be\n",
      "separated  Is stop word/punctuation ? False  POS  VERB Lemma  separate\n",
      "from  Is stop word/punctuation ? True  POS  ADP Lemma  from\n",
      "my  Is stop word/punctuation ? True  POS  DET Lemma  -PRON-\n",
      "wrist  Is stop word/punctuation ? False  POS  NOUN Lemma  wrist\n",
      ".  Is stop word/punctuation ? True  POS  PUNCT Lemma  .\n",
      "----\n",
      "There  Is stop word/punctuation ? True  POS  PRON Lemma  there\n",
      "were  Is stop word/punctuation ? True  POS  AUX Lemma  be\n",
      "two other  Is stop word/punctuation ? False  POS  NUM Lemma  two other\n",
      "cars  Is stop word/punctuation ? False  POS  NOUN Lemma  car\n",
      ".  Is stop word/punctuation ? True  POS  PUNCT Lemma  .\n",
      "\"  Is stop word/punctuation ? True  POS  PUNCT Lemma  \"\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print('----')\n",
    "    for token in sentence:\n",
    "        print(token.text,' Is stop word/punctuation ?',token.is_stop or token.is_punct , ' POS ', token.pos_, 'Lemma ', token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I pulled out of my parking spot, turned right out of the parking lot, then proceeded to the next stop sign.\n",
      "sentence1.svg\n",
      "While looking both ways I noticed a white truck in the far distance and proceeded to roll forward and take the left turn.\n",
      "sentence2.svg\n",
      "As I turned I was t-boned on the front driver side by the white truck, which turned out to be a Ford F-450 commercial truck.\n",
      "sentence3.svg\n",
      "All I remember hearing was the rumbling of crushing metal.\n",
      "sentence4.svg\n",
      "Needless to say my beloved car that I had worked so hard for appeared to be totaled.\n",
      "sentence5.svg\n",
      "All of my airbags deployed, my front windshield was smashed  in, the driver’s window was broken, my key jammed in the ignition, and I was unconscious.\n",
      "sentence6.svg\n",
      "When I came to my first reaction was hysterics.\n",
      "sentence7.svg\n",
      "I looked around for a minute, heard voices talking to me, then I felt an unbearable pain in my right hand.\n",
      "sentence8.svg\n",
      "As I looked down at my hand I noticed that it appeared to be separated from my wrist.\"\n",
      "sentence9.svg\n"
     ]
    }
   ],
   "source": [
    "i= 0 \n",
    "from pathlib import Path\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    i +=1\n",
    "    print(sentence)\n",
    "    # displaying tokens with their POS tags\n",
    "    \n",
    "#     displacy.render(sentence,style='dep',jupyter=True)\n",
    "    svg = displacy.render(sentence, style=\"dep\", jupyter=False)\n",
    "\n",
    "    output_path = Path(\"sentence{}.svg\".format(i))\n",
    "    print(output_path)\n",
    "    output_path.open(\"w\", encoding=\"utf-8\").write(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddatta/anaconda3/envs/text/lib/python3.7/site-packages/spacy/displacy/__init__.py:189: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I pulled out of my parking spot, turned right out of the parking lot, then proceeded to the next stop sign. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">While looking both ways I noticed a white truck in the far distance and proceeded to roll forward and take the left turn. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">As I turned I was t-boned on the front driver side by \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the white truck\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", which turned out to be a \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ford F-450 commercial\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " truck. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">All I remember hearing was the rumbling of crushing metal. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Needless to say my beloved car that I had worked so hard for appeared to be totaled. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">All of my airbags deployed, my front windshield was smashed  in, the driver’s window was broken, my key jammed in the ignition, and I was unconscious. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When I came to my \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " reaction was hysterics. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I looked around for a minute, heard voices talking to me, then I felt an unbearable pain in my right hand. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">As I looked down at my hand I noticed that it appeared to be separated from my wrist.&quot;</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    displacy.render(sentence, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "---\n",
      "my parking spot\n",
      ">> park\n",
      ">> spot\n",
      "---\n",
      "the parking lot\n",
      ">> park\n",
      ">> lot\n",
      "---\n",
      "the next stop sign\n",
      ">> next\n",
      ">> stop\n",
      ">> sign\n",
      "---\n",
      "both ways\n",
      ">> way\n",
      "---\n",
      "I\n",
      "---\n",
      "a white truck\n",
      ">> white\n",
      ">> truck\n",
      "---\n",
      "the far distance\n",
      ">> far\n",
      ">> distance\n",
      "---\n",
      "the left turn\n",
      ">> left\n",
      ">> turn\n",
      "---\n",
      "I\n",
      "---\n",
      "I\n",
      "---\n",
      "the front driver side\n",
      ">> front\n",
      ">> driver\n",
      ">> side\n",
      "---\n",
      "the white truck\n",
      "entity [the white truck] ORG\n",
      ">> white\n",
      ">> truck\n",
      "---\n",
      "a Ford F-450 commercial truck\n",
      "entity [Ford F-450 commercial] PRODUCT\n",
      ">> Ford F-450 commercial\n",
      ">> truck\n",
      "---\n",
      "I\n",
      "---\n",
      "the rumbling\n",
      ">> rumbling\n",
      "---\n",
      "metal\n",
      ">> metal\n",
      "---\n",
      "my beloved car\n",
      ">> beloved\n",
      ">> car\n",
      "---\n",
      "I\n",
      "---\n",
      "my airbags\n",
      ">> airbag\n",
      "---\n",
      "my front windshield\n",
      ">> front\n",
      ">> windshield\n",
      "---\n",
      "the driver’s window\n",
      ">> driver’s\n",
      ">> window\n",
      "---\n",
      "the ignition\n",
      ">> ignition\n",
      "---\n",
      "I\n",
      "---\n",
      "I\n",
      "---\n",
      "my first reaction\n",
      "entity [first] ORDINAL\n",
      ">> first\n",
      ">> reaction\n",
      "---\n",
      "I\n",
      "---\n",
      "a minute\n",
      ">> minute\n",
      "---\n",
      "voices\n",
      ">> voice\n",
      "---\n",
      "me\n",
      "---\n",
      "I\n",
      "---\n",
      "an unbearable pain\n",
      ">> unbearable\n",
      ">> pain\n",
      "---\n",
      "my right hand\n",
      ">> right\n",
      ">> hand\n",
      "---\n",
      "I\n",
      "---\n",
      "my hand\n",
      ">> hand\n",
      "---\n",
      "I\n",
      "---\n",
      "it\n",
      "---\n",
      "my wrist\n",
      ">> wrist\n",
      "---\n",
      "two other cars\n",
      "entity [two other] CARDINAL\n",
      ">> two other\n",
      ">> car\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "nounPhrase_posExclude = ['PRON', 'DET', 'PART']\n",
    "candidate_spans = []\n",
    "for sentence in doc.sents:\n",
    "    for spanChunk in sentence.noun_chunks:\n",
    "        print(spanChunk.text)\n",
    "        # process the span\n",
    "        if len(spanChunk.ents)>0 :\n",
    "            print('entity', spanChunk.ents, spanChunk.ents[0].label_ )\n",
    "        cur_span = []\n",
    "        \n",
    "        for item in spanChunk:\n",
    "            if item.pos_ not in nounPhrase_posExclude:\n",
    "                print('>>', item.lemma_)\n",
    "                cur_span.append(item)\n",
    "        if len(cur_span) > 0:\n",
    "            candidate_spans.append(cur_span)\n",
    "        \n",
    "        print('---')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0711     1  first\n",
      "[first]\n",
      "0.0687     1  a ford f-450 commercial truck\n",
      "[a Ford F-450 commercial truck]\n",
      "0.0679     1  the front driver side\n",
      "[the front driver side]\n",
      "0.0630     1  voices\n",
      "[voices]\n",
      "0.0577     1  ford\n",
      "[Ford]\n",
      "0.0577     1  f-450\n",
      "[F-450]\n",
      "0.0556     1  my front windshield\n",
      "[my front windshield]\n",
      "0.0541     1  metal\n",
      "[metal]\n",
      "0.0532     1  the next stop sign\n",
      "[the next stop sign]\n",
      "0.0516     1  a white truck\n",
      "[a white truck]\n",
      "0.0498     1  my first reaction\n",
      "[my first reaction]\n",
      "0.0496     1  my beloved car\n",
      "[my beloved car]\n",
      "0.0468     1  an unbearable pain\n",
      "[an unbearable pain]\n",
      "0.0452     1  two other cars\n",
      "[two other cars]\n",
      "0.0441     1  my parking spot\n",
      "[my parking spot]\n",
      "0.0438     1  the parking lot\n",
      "[the parking lot]\n",
      "0.0423     1  the far distance\n",
      "[the far distance]\n",
      "0.0418     1  the left turn\n",
      "[the left turn]\n",
      "0.0415     1  my right hand\n",
      "[my right hand]\n",
      "0.0408     2  the white truck\n",
      "[the white truck, the white truck]\n",
      "0.0340     1  the rumbling\n",
      "[the rumbling]\n",
      "0.0339     1  the driver’s window\n",
      "[the driver’s window]\n",
      "0.0301     1  both ways\n",
      "[both ways]\n",
      "0.0285     1  my hand\n",
      "[my hand]\n",
      "0.0278     1  a minute\n",
      "[a minute]\n",
      "0.0247     1  the ignition\n",
      "[the ignition]\n",
      "0.0240     1  my wrist\n",
      "[my wrist]\n",
      "0.0230     1  my airbags\n",
      "[my airbags]\n",
      "0.0000    15  i\n",
      "[I, I, I, I, I, I, I, I, I, me, I, I, I, it, two]\n"
     ]
    }
   ],
   "source": [
    "# add PyTextRank to the spaCy pipeline\n",
    "tr = pytextrank.TextRank()\n",
    "try:\n",
    "    nlp.add_pipe(tr.PipelineComponent, name=\"textrank\", last=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "doc1 = nlp(text)\n",
    "\n",
    "# examine the top-ranked phrases in the document\n",
    "for p in doc1._.phrases:\n",
    "    print(\"{:.4f} {:5d}  {}\".format(p.rank, p.count, p.text))\n",
    "    print(p.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7f88a7e04f10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yields', 0.96498042345047),\n",
       " ('yielding', 0.9228639006614685),\n",
       " ('yielded', 0.8758969902992249),\n",
       " ('6.25', 0.8733323216438293),\n",
       " ('3.75', 0.8696194887161255),\n",
       " ('maturity', 0.8650699257850647),\n",
       " ('benchmark', 0.8637473583221436),\n",
       " ('bond', 0.8622376918792725),\n",
       " ('higher', 0.8615794777870178),\n",
       " ('5.75', 0.8570329546928406)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.most_similar('car')\n",
    "glove_model.most_similar_cosmul('yield')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[my right hand: [my right hand, my hand], As: [As, it]]\n"
     ]
    }
   ],
   "source": [
    "print(doc._.coref_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adposition : ADP : prpeopsition + postposition ; occurs with anoun phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I pulled out of my parking spot, turned right out of the parking lot, then proceeded to the next stop sign.\n",
      "> pulled\n",
      "While looking both ways I noticed a white truck in the far distance and proceeded to roll forward and take the left turn.\n",
      "> noticed\n",
      "As I turned I was t-boned on the front driver side by the white truck, which turned out to be a Ford F-450 commercial truck.\n",
      "> turned\n",
      "> turned\n",
      "All I remember hearing was the rumbling of crushing metal.\n",
      "> remember\n",
      "Needless to say my beloved car that I had worked so hard for appeared to be totaled.\n",
      "> worked\n",
      "All of my airbags deployed, my front windshield was smashed  in, the driver’s window was broken, my key jammed in the ignition, and I was unconscious.\n",
      "> deployed\n",
      "> jammed\n",
      "When I came to my first reaction was hysterics.\n",
      "> came\n",
      "I looked around for a minute, heard voices talking to me, then I felt an unbearable pain in my right hand.\n",
      "> looked\n",
      "> talking\n",
      "> felt\n",
      "As I looked down at my hand I noticed that it appeared to be separated from my wrist.\n",
      "> looked\n",
      "> noticed\n",
      "> appeared\n",
      "There were two other cars.\"\n",
      "{deployed, noticed, worked, remember, looked, looked, noticed, felt, turned, appeared, talking, turned, pulled, came, jammed}\n"
     ]
    }
   ],
   "source": [
    "from spacy.symbols import nsubj, amod, VERB, ADJ, ADP, DET\n",
    "verbs = set()\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)\n",
    "    for cand_subject in sentence:\n",
    "        if cand_subject.dep == nsubj and cand_subject.head.pos == VERB:\n",
    "            verbs.add(cand_subject.head)\n",
    "            print('>', cand_subject.head)\n",
    "#         if cand_subject.dep == amod  or ( cand_subject.pos == ADJ or cand_subject.head.pos == ADP):\n",
    "#             print('>>', cand_subject.lemma_)\n",
    "print(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "I pulled out of my parking spot, turned right out of the parking lot, then proceeded to the next stop sign.\n",
      "---->\n",
      "----\n",
      "While looking both ways I noticed a white truck in the far distance and proceeded to roll forward and take the left turn.\n",
      "---->\n",
      "to roll forward and take the left turn | roll VERB\n",
      "----\n",
      "As I turned I was t-boned on the front driver side by the white truck, which turned out to be a Ford F-450 commercial truck.\n",
      "---->\n",
      "to be a Ford F-450 commercial truck | be AUX\n",
      "----\n",
      "All I remember hearing was the rumbling of crushing metal.\n",
      "---->\n",
      "hearing | hearing VERB\n",
      "----\n",
      "Needless to say my beloved car that I had worked so hard for appeared to be totaled.\n",
      "---->\n",
      "to say my beloved car that I had worked so hard for appeared to be totaled | say VERB\n",
      "to be totaled | totaled VERB\n",
      "----\n",
      "All of my airbags deployed, my front windshield was smashed  in, the driver’s window was broken, my key jammed in the ignition, and I was unconscious.\n",
      "---->\n",
      "All of my airbags deployed | deployed VERB\n",
      "----\n",
      "When I came to my first reaction was hysterics.\n",
      "---->\n",
      "----\n",
      "I looked around for a minute, heard voices talking to me, then I felt an unbearable pain in my right hand.\n",
      "---->\n",
      "I looked around for a minute, heard voices talking to me | looked VERB\n",
      "voices talking to me | talking VERB\n",
      "----\n",
      "As I looked down at my hand I noticed that it appeared to be separated from my wrist.\n",
      "---->\n",
      "that it appeared to be separated from my wrist | appeared VERB\n",
      "to be separated from my wrist | separated VERB\n",
      "----\n",
      "There were two other cars.\"\n",
      "---->\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print('----')\n",
    "    print(sentence)\n",
    "    print('---->')\n",
    "    for word in sentence:\n",
    "        if word.dep_ in (\"xcomp\", \"ccomp\"):\n",
    "            subtree_span = doc[ word.left_edge.i : word.right_edge.i + 1]\n",
    "            print(subtree_span.text, \"|\", subtree_span.root.text, subtree_span.root.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Count the number of vehicles\n",
    "# -------------------------------\n",
    "# Assume a narrative text\n",
    "# -------------------------------\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "vehicle_seed_words = ['car','vehicle','automoile','bus','minivan','truck','motorcycle','minivan', 'bike','cycle']\n",
    "vehicle_synonyms = [ ]\n",
    "for veh_w in vehicle_seed_words: \n",
    "    try:\n",
    "        vehicle_synonyms.extend([ lemmatizer.lemmatize(_[0])  for _ in  glove_model.most_similar(veh_w)])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "from collections import Counter\n",
    "vehicle_synonyms= [ v for v,count in Counter(vehicle_synonyms).items() if count > 1 ]\n",
    "vehicle_synonyms\n",
    "# Human exper based pruning\n",
    "vehicle_synonyms.remove('driver')\n",
    "vehicle_synonyms.remove('driving')\n",
    "vehicle_synonyms.remove('parked')\n",
    "vehicle_synonyms.remove('dealership')\n",
    "def indicates_vehicle(cur_word):\n",
    "    global vehicle_synonyms\n",
    "    if cur_word in vehicle_synonyms:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# A simple rule based detector\n",
    "# ----------------------------------\n",
    "# Disadvantages ? \n",
    "# 1. Negation handling is difficult\n",
    "# ----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_phrases = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> I pulled out of my parking spot, turned right out of the parking lot, then proceeded to the next stop sign.\n",
      "> While looking both ways I noticed a white truck in the far distance and proceeded to roll forward and take the left turn.\n",
      "[det] truck NOUN\n",
      "> As I turned I was t-boned on the front driver side by the white truck, which turned out to be a Ford F-450 commercial truck.\n",
      "[det] truck PROPN\n",
      "[det] truck NOUN\n",
      "> All I remember hearing was the rumbling of crushing metal.\n",
      "> Needless to say my beloved car that I had worked so hard for appeared to be totaled.\n",
      "[det] NOUN car\n",
      "> All of my airbags deployed, my front windshield was smashed  in, the driver’s window was broken, my key jammed in the ignition, and I was unconscious.\n",
      "> When I came to my first reaction was hysterics.\n",
      "> I looked around for a minute, heard voices talking to me, then I felt an unbearable pain in my right hand.\n",
      "> As I looked down at my hand I noticed that it appeared to be separated from my wrist.\n",
      "> There were two other cars.\"\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print( '>', sentence )\n",
    "    for word in sentence:\n",
    "        # ----------------\n",
    "        # Rule to check for the narrator's reference to vehicles\n",
    "        # e.g. \"our truck\" \n",
    "        # ----------------\n",
    "        if word.dep_ == \"poss\" and word.pos_ == \"DET\": \n",
    "            # words like my, ours, etc\n",
    "            if indicates_vehicle(word.head.lemma_):\n",
    "                print('[det]',  word.head.pos_, word.head)\n",
    "                cur_phrase = ('[det]',word.head.lemma_)\n",
    "                if cur_phrase not in seen_phrases:\n",
    "                    seen_phrases.append(cur_phrase)\n",
    "        # Handle phrases like : \"the * car\"\n",
    "        elif word.dep_ == \"det\" and word.pos_ == \"DET\":\n",
    "             if indicates_vehicle(word.head.lemma_) :\n",
    "                print('[det]', word.head,  word.head.pos_)\n",
    "                cur_phrase = ('[det]',  word.head.lemma_)\n",
    "                seen_phrases.append(cur_phrase)\n",
    "        # Handle phrases like \"three more cars ..\"\n",
    "        elif word.pos == 'NUM' or word.dep_=='nummod':\n",
    "            # check if there is no poss child of the head like \"ours\"\n",
    "            flag = True\n",
    "            indicates_vehicle(word.head.lemma_)\n",
    "            for c in word.head.children:\n",
    "                if c!=word and c.dep_== \"poss\":\n",
    "                    flag = False\n",
    "            if flag:\n",
    "                cur_phrase = ('[COUNT:{}]'.format(word.text), word.head.lemma_ )\n",
    "                seen_phrases.append(cur_phrase)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two or more\n"
     ]
    }
   ],
   "source": [
    "if len(set(seen_phrases)) > 2:\n",
    "    print(\"Two or more\")\n",
    "elif len(set(seen_phrases)) == 1:\n",
    "    print('single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Create a graph \n",
    "# -----------------------------------\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Keep refereal types as determinants\n",
    "# types  \n",
    "# 1 {'my','ours'}\n",
    "# 2 {their}\n",
    "# 3 {the, that a, an}\n",
    "# ===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref_type(_txt_):\n",
    "    \n",
    "    if _txt_ in ['my','our','mine']:\n",
    "        return 1\n",
    "    elif _txt_ in ['their']:\n",
    "        return 2\n",
    "    elif _txt_ in ['the', 'that', 'a', 'an']:\n",
    "        return 3\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def indicates_contact(text):\n",
    "    candidates = ['rear-ended','hit','strike','crash','struck','collide','t-boned']\n",
    "    return text in candidates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chain-driven', 0.7046515345573425),\n",
       " ('engine-powered', 0.6801375150680542),\n",
       " ('atr-42', 0.6755519509315491),\n",
       " ('mid-air', 0.6702165603637695),\n",
       " ('motor-driven', 0.6601287722587585),\n",
       " ('out-of-control', 0.6502394676208496),\n",
       " ('parkinsonian', 0.6491718888282776),\n",
       " ('vbied', 0.6469529867172241),\n",
       " ('basepath', 0.6467806100845337),\n",
       " ('carry-over', 0.6454182863235474)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.most_similar('rear-end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node_obj:\n",
    "    _id = -1\n",
    "    \n",
    "    def __init__(self, ref, txt):\n",
    "        \n",
    "        self.id = node_obj._id + 1\n",
    "        node_obj._id += 1\n",
    "        \n",
    "        self.text = txt\n",
    "        self.ref = ref\n",
    "        self.object_type = 'entity'\n",
    "        self.attr = []\n",
    "        return \n",
    "    \n",
    "        \n",
    "    def add_attr(self, attr):\n",
    "        self.attr.append(attr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node(_ref_, _txt_):\n",
    "    _exists = False\n",
    "    global node_list\n",
    "    for obj in node_list :\n",
    "        if obj.ref == _ref_ and obj.text == _txt_:  \n",
    "            _exists = True\n",
    "            return obj\n",
    "    \n",
    "    if not _exists:\n",
    "        obj =  node_obj(_ref_ , _txt_)\n",
    "        node_list.append(\n",
    "           obj\n",
    "        )\n",
    "    return obj\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I pulled out of my \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    parking spot\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       ", turned right out of the \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    parking lot\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       ", then proceeded to the \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    next stop sign\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">While looking both \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ways\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       " I noticed a \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    white truck\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       " in the \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    far distance\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       " and proceeded to roll forward and take the \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    left turn\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB indicating collision event ::  t-boned\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">As I turned I was t-boned on the \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    front driver side\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       " by the \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    white truck\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       ", which turned out to be a \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ford F-450 commercial truck\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">All I remember hearing was the \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    rumbling\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       " of crushing \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    metal\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Needless to say my \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    beloved car\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       " that I had worked so hard for appeared to be totaled.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">All of my \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    airbags\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       " deployed, my \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    front windshield\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       " was smashed  in, the \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    driver’s window\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       " was broken, my key jammed in the \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ignition\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       ", and I was unconscious.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When I came to my \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first reaction\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       " was hysterics.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I looked around for a \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    minute\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       ", heard \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    voices\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       " talking to me, then I felt an \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    unbearable pain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       " in my \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    right hand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">As I looked down at my \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       " I noticed that it appeared to be separated from my \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    wrist\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">There were \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF11, #FFF252); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two other cars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       ".&quot;</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node_list = []\n",
    "nounPhrase_posExclude = ['PRON', 'DET', 'PART']\n",
    "candidate_spans = []\n",
    "disp_sentence = []\n",
    "\n",
    "# ===============================\n",
    "# Process each sentence\n",
    "# ===============================\n",
    "for sentence in doc.sents:         \n",
    "    disp_sentence = []\n",
    "    disp_sentence.append({'text':sentence.text,'ents' :[] })\n",
    "    objs = []\n",
    "    for spanChunk in sentence.noun_chunks:\n",
    "        for word in spanChunk:\n",
    "            if word.dep_ == \"poss\" and word.pos_ == \"DET\": \n",
    "                head_token = word.head\n",
    "                # words like my, ours, etc\n",
    "                if head_token.pos_ =='NOUN' and indicates_vehicle(head_token.lemma_):\n",
    "                    _ref_ = get_ref_type( word.lemma_)\n",
    "                    _txt_ =  head_token.lemma_\n",
    "                    obj = add_node( _ref_, head_token.lemma_)\n",
    "                    obj.type = 'vehicle'\n",
    "                    objs.append(obj)\n",
    "                    continue      \n",
    "                              \n",
    "            elif word.pos_ == \"DET\" : \n",
    "                head_token = word.head\n",
    "                \n",
    "                if (head_token.pos_ == 'PROPN' or head_token.pos_ == 'NOUN') and indicates_vehicle(head_token.lemma_):\n",
    "                    \n",
    "                    _ref_ = get_ref_type(word.lemma_)\n",
    "                    _txt_ =  head_token.lemma_\n",
    "                    obj = add_node( _ref_, head_token.lemma_)\n",
    "                    obj.type = 'vehicle'\n",
    "                    objs.append(obj)\n",
    "                    continue   \n",
    "                \n",
    "        # ------------------------\n",
    "        # Identify the entities \n",
    "        # ------------------------\n",
    "        if len(spanChunk.ents) > 0 :\n",
    "            for c_ent in spanChunk.ents:\n",
    "                # identify products :e.g (Chevrolet) Impala\n",
    "                if c_ent.label_ == 'PRODUCT' and (doc[c_ent.start].head.pos_=='NOUN' or doc[c_ent.start].head.pos_=='PROPN'): \n",
    "                    head_token = doc[c_ent.start].head\n",
    "                    _ref_ = get_ref_type(head_token.left_edge.text) # the determinant\n",
    "                    _txt_ = head_token.lemma_\n",
    "                    # check if the entity has been added\n",
    "                    obj =  add_node(_ref_, _txt_)\n",
    "                    obj.add_attr((c_ent.label_ ,c_ent.text))\n",
    "                    objs.append(obj)\n",
    "                    \n",
    "                # terms such as \"first bus\" or \"second car\" can be assumed that the entity has been previously referenced.\n",
    "                elif c_ent.label_ == 'ORDINAL': \n",
    "                    head_token = doc[c_ent.start].head\n",
    "                    if head_token.pos_ == 'NOUN':\n",
    "                         pass\n",
    "                    \n",
    "                # terms such as \"two\" or \"three\"    \n",
    "                elif c_ent.label_ == 'CARDINAL':\n",
    "                    head_token = doc[c_ent.start].head\n",
    "                    pass\n",
    "                \n",
    "                # terms such as \"4:30 p.m.\"\n",
    "                elif c_ent.label_ == 'TIME':\n",
    "                    token = doc[c_ent.start]\n",
    "                    pass\n",
    "           \n",
    "        # ---- Visualize \n",
    "        cur_span = []\n",
    "        for item in spanChunk:\n",
    "            if item.pos_ not in nounPhrase_posExclude:\n",
    "                cur_span.append(item)\n",
    "\n",
    "        if len(cur_span) > 0:\n",
    "            candidate_spans.append(cur_span)\n",
    "            disp_sentence[0]['ents'].append({\n",
    "                'start': cur_span[0].idx - sentence[0].idx ,\n",
    "                'end': cur_span[-1].idx - sentence[0].idx + len( cur_span[-1].text),\n",
    "                'label': ''\n",
    "                }\n",
    "            )\n",
    "    for word in sentence:\n",
    "        if word.pos_=='VERB' and indicates_contact(word.lemma_):\n",
    "            print('VERB indicating collision event :: ', word.lemma_)\n",
    "        \n",
    "        \n",
    "    colors = {\"\": \"linear-gradient(10deg, #00FF11, #FFF252)\"}\n",
    "    options = {\"ents\": [\"\"], \"colors\": colors}\n",
    "    displacy.render(disp_sentence, style='ent', manual=True, options=options)           \n",
    "           \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck vehicle [('PRODUCT', 'Ford F-450 commercial')]\n",
      "car vehicle []\n"
     ]
    }
   ],
   "source": [
    "for _ in node_list: \n",
    "    print(_.text,_.type,_.attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB indicating collision event ::  t-boned\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">As I turned I was \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(10deg, #00FF00, #00FFFF); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    t-boned\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\"></span>\n",
       "</mark>\n",
       " on the front driver side by the white truck, which turned out to be a Ford F-450 commercial truck.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for sentence in doc.sents: \n",
    "    flag = False\n",
    "    disp_sentence = [{'text':sentence.text,'ents' :[] }]\n",
    "    for word in sentence:\n",
    "        if word.pos_=='VERB' and indicates_contact(word.lemma_):\n",
    "            print('VERB indicating collision event :: ', word.lemma_)\n",
    "            flag = True\n",
    "            disp_sentence[0]['ents'].append({\n",
    "                'start': word.idx - sentence[0].idx ,\n",
    "                'end':   word.idx - sentence[0].idx + len( word.text),\n",
    "                'label': ''\n",
    "                }\n",
    "            )\n",
    "    if flag:\n",
    "        colors = {\"\": \"linear-gradient(10deg, #00FF00, #00FFFF)\"}\n",
    "        options = {\"ents\": [\"\"], \"colors\": colors}        \n",
    "        displacy.render(disp_sentence, style='ent', manual=True, options=options)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
